{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oppgave 1**\n",
    "\n",
    "*Første steg - setup*\n",
    "\n",
    "Definerer først variabler. Setter ned en vilkårlig `maxiter` siden oppgaveteksten ba om det. Redfinerer også $x_0$ til ny variabel for ordens skyld. Bør også nevne at `prevx` først deklareres som `np.inf`, slik at while-løkken alltid kjøres minst én gang.\n",
    "\n",
    "*Neste steg - iterasjon*\n",
    "Begge funksjonene virker likt her, bare med en ulik $g(x)$. I while-løkka sjekkes først om iterasjonen er overskredet `maxiter`, hvorav man returnerer 0 for begge variabler. Ellers settes $x_{i+1}=g(x_i)$ som vanlig fikspunktiterasjon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.33473414194323614, 7) <- Fikspunkt\n",
      "(0.33473414194335266, 4) <- Newtons m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "    \n",
    "def fiksit(x0,tol):\n",
    "    def g(x):\n",
    "        return 1/3*((x**5)+1)\n",
    "    assert tol>0\n",
    "    iter = 0\n",
    "    maxiter = 20\n",
    "    x = x0 \n",
    "    prevx =np.inf \n",
    "    while abs(x-prevx) > tol:\n",
    "        if iter > maxiter:\n",
    "            return 0,0 \n",
    "        iter +=1\n",
    "        prevx = x\n",
    "        x = g(x)        \n",
    "    return x,iter\n",
    "\n",
    "def newton(x0,tol):\n",
    "    #Setup: Definerer variable\n",
    "    def g(x):\n",
    "        return x-(x**5-3*x+1)/(5*x**4-3)\n",
    "    assert tol>0\n",
    "    x = x0\n",
    "    prevx = np.inf\n",
    "    maxiter = 50\n",
    "    iter = 0\n",
    "    \n",
    "    #Her begynner iterasjonen:\n",
    "    while abs(x-prevx) > tol:\n",
    "        if iter > maxiter:\n",
    "            return 0,0 #Avsluttes etter maxiter\n",
    "        iter +=1\n",
    "        prevx = x\n",
    "        x = g(x)\n",
    "    return x,iter\n",
    "\n",
    "\n",
    "\n",
    "print(fiksit(0,10**(-10)), \"<- Fikspunkt\")\n",
    "print(newton(0,10**(-10)), \"<- Newtons m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kontrollspørsmål 1*: Fikspunktiterasjon bruker $7$ iterasjoner, Newtons metode bruker $4$ iterasjoner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oppgave 2**\n",
    "\n",
    "Brukte `!pip install autograd` for å laste ned `autograd`-modulen. Ellers implementeres det likt fikspunktiterasjon, bare at\n",
    "\n",
    "$$x_{i+1}=x_i-\\frac{f(x_i)}{f'(x_i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.7180861141125476, 4)\n",
      "(2.0376244457683277, 4)\n",
      "(4.24303676441417, 5)\n",
      "(8.323364548870096, 5)\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import value_and_grad\n",
    "\n",
    "def f(x):\n",
    "    return 1/3*np.sqrt(1+np.sin(np.tanh(x)))+np.cos(x)\n",
    "\n",
    "def gNewton(f, x0, tol):\n",
    "    assert tol>0\n",
    "    iter = 0\n",
    "    x = x0/1.0 #Tvinger input til float før derivasjon\n",
    "    prevx = np.inf\n",
    "    \n",
    "    while abs(x-prevx) > tol:\n",
    "        Dg = value_and_grad(f)\n",
    "        G = Dg(x/1.0)\n",
    "        iter +=1\n",
    "        prevx = x\n",
    "        x = x-f(x)/G[1]\n",
    "    return x, iter\n",
    "\n",
    "# Utfør påkrevde tester under her\n",
    "x0 = [-2.0, 2.0, 4.0, 8.0]\n",
    "for x in x0:\n",
    "    print(gNewton(f, x, 10**(-10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kontrollspørsmål 2:*\n",
    "Ser at det er $4$ forskjellige røtter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Åttende desimal er for røttene 6 og 6\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import jacobian\n",
    "import numpy.linalg as la\n",
    "\n",
    "def f(x):\n",
    "    return np.array([x[0]**2+x[1]**2-1, x[0]**3-x[1]])\n",
    "def sNewton(f, x0, tol):\n",
    "    x = x0/1.0\n",
    "    Df = jacobian(f)\n",
    "    iter = 0\n",
    "    delta = np.array([np.inf]) #initverdi > tol for all tol\n",
    "    while la.norm(delta) > tol:\n",
    "        delta = la.solve(Df(x),-f(x)) #Step 1, løse mhp delta\n",
    "        x += delta #Step 2: x_{i+1} += delta\n",
    "        iter +=1\n",
    "    return x, iter\n",
    "sol=sNewton(f,np.array([1,1]),10**(-10))\n",
    "root1, root2 = str(round(sol[0][0],8)), str(round(sol[0][1],8))\n",
    "print(\"Åttende desimal er for røttene\", root1[-1], \"og\", root2[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kontrollspørsmål 3* Det åttende desimalet er 6 for begge røttene"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
